#!/usr/bin/env python
# coding: utf-8

# mission to mars
# 

# In[23]:


from bs4 import BeautifulSoup as bs
from splinter import Browser
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import requests


# In[24]:



executable_path = {'executable_path': ChromeDriverManager().install()}
browser = Browser('chrome', **executable_path, headless=False)


# In[25]:


mars_news_site = "https://mars.nasa.gov/news/"
# mars_page = requests.get(mars_news_site)
# mars_page
browser.visit(mars_news_site)
html = browser.html
soup = bs(html,'html.parser')


# In[26]:


# soup = BeautifulSoup(mars_page.content,'html.parser')
# print(soup.prettify())


# In[27]:


news_title = soup.find_all("div", class_="list_text")
news_title[0]


# In[28]:


title= news_title[0].find("div",class_='content_title').get_text()
paragraph = news_title[0].find("div",class_='article_teaser_body').get_text()
print(title)
print(paragraph)


# ## Use Splinter to work with JPL website

# In[29]:


# find featured image
target_site = 'https://spaceimages-mars.com'


# In[30]:


executable_path = {'executable_path': ChromeDriverManager().install()}
browser = Browser('chrome', **executable_path, headless=False)
browser.visit(target_site)

html = browser.html
soup = bs(html,'html.parser')

#featured_image_url = browser.find_by_partial_text('featured').value
featured_image_url = target_site + soup.find('img', class_='headerimage fade-in')['src']
print(featured_image_url)
browser.quit()


# ### get facts about mars use pandas to get data from https://galaxyfacts-mars.com
# 
# 

# In[44]:


mars_facts = "https://galaxyfacts-mars.com"


# In[45]:


mars_series = pd.read_html(mars_facts)
# There are two tables on this page, read the first one
mars_df = mars_series[1]
mars_df.columns = ['Label', 'Mars']
mars_df.set_index('Label', inplace=True)
#drop index.name to avoid funky second index header row
mars_df.index.name=None
mars_df


# In[46]:


# create html version of pandas table
html_table = mars_df.to_html(index=False, header=False, classes="table table-striped")


# In[47]:


print(html_table)


# In[48]:


browser.quit()


# ## Mars Hemispheres
# ### get data from astrogeology site. Get the image url for the full resolution of each hemisphere. 
# ### Save the image url and the hemisphere title and store in a python dictionary
# ### Append the dictionary to a list. The list will contain one dictionary for each hemisphere
# ### https://marshemispheres.com

# In[85]:


from time import sleep
executable_path = {'executable_path': ChromeDriverManager().install()}
browser = Browser('chrome', **executable_path, headless=False)
#hemisphere_url = 'https://marshemispheres.com'
#browser.visit(hemisphere_url)
#set the URL and request
hemi_url = 'https://marshemispheres.com'
# hemi_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'
# hemi_response = requests.get(hemi_url)
browser.visit(hemi_url)


# In[86]:


#parse the landing page, isolate the image links in the item div
hemi_html = browser.html
hemi_soup = bs(hemi_html, "html.parser")
hemi_links = hemi_soup.find_all("div", class_ = "item")

#create a list for the names and image links
hemi_img_urls = []

#loop thru each link and grab the name and full size image
for link in hemi_links:
    #dictionary to hold the name/link pairs
    hemi_dict = {}
    #name is in the h3 text
    img_name = link.find("h3").text
    #link is in each desctiption, a href
    img_link = link.find("div", class_ = "description").a["href"]
    #add the base url
    # link_base = "https://astrogeology.usgs.gov"
    link_base = hemi_url
    visit_link = link_base +"/"+ img_link
    #visit the link
    browser.visit(visit_link)
    #don't go too fast
    time.sleep(5)
    
    #parse the html
    indv_hemi_html = browser.html
    indv_hemi_soup = bs(indv_hemi_html, 'html.parser')
    
    #grab the full image link from wide-image src
    indv_hemi_url = indv_hemi_soup.find("img", class_ = "wide-image")["src"]
    
    #add to dictionary as hemi_img_name, hemi_img_url
    hemi_dict['hemi_img_name'] = img_name
    hemi_dict['hemi_img_url'] = link_base + indv_hemi_url
    hemi_dict['hemi_source_url'] = visit_link
    #put dictionary into hemi_img_urls
    hemi_img_urls.append(hemi_dict)
    browser.back()


# In[90]:


hemi_img_urls


# In[91]:


browser.quit()


# In[ ]:




